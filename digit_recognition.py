"""MNIST Digit Recognizer

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fvcOP2gecQCZOvpX5OGeyw2jjuCbuZkn

"""
### Importing necessary libraries

# Data Manipulation library
import numpy as np 
import pandas as pd

# Data visualisation libraries
import matplotlib.pyplot as plt 
import seaborn as sns 

# Image Manipulation 
import cv2 as cv

# Evaluation and Splitting 
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

# Deep Learning Libraries
import keras 
from keras.models import Sequential
from keras.layers import Dense, Flatten, Dropout, Conv2D, Lambda, MaxPooling2D
from keras.preprocessing.image import ImageDataGenerator
from keras.utils.np_utils import to_categorical

# Uploading Data 
from google.colab import files 
files.upload()

# Loading Data 
train_data = pd.read_csv('train.csv')
test_data = pd.read_csv('test.csv')

# Make original data copies 
train_og = train_data.copy() 
test_og = test_data.copy() 
print(train_data.shape, test_data.shape)

# Sample of the data 
print(train_data.head())
print(test_data.head())

# Extract only the feature values
X = train_data.drop(['label'], axis = 1).values
y = train_data['label'].values
test_X = test_data.values

# Grayscale Normalization 
X = X / 255.0
test_X = test_X / 255.0

# Reshape the image data into 3 dimensions (height = 28pixels, width = 28px, 1)
# because 28 x 28 = 784 
X = X.reshape(-1, 28, 28, 1)
test_X = test_X.reshape(-1, 28, 28, 1)

"""Encoding"""

# One hot encode the labels. There are 10 labels so we add 10 new dimensions
y = to_categorical(y)
print(y.shape)

# Train and validation splits 
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=324)
print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)

# Visulaisation of the data 
images = X_train.reshape(X_train.shape[0], 28, 28)

fig, axis = plt.subplots(1, 5, figsize=(20, 10))
for i, ax in enumerate(axis.flat):
    ax.imshow(images[i], cmap = 'binary')
    digit = y_train[i].argmax()   # finding the number where the array has a 1 which will be the max value
    ax.set(title = f"The number is {digit}")

"""Building the CNN"""

# Important parameters
epochs = 50
batch_size = 64

# Building the CNN Model
model = Sequential() 
model.add(Conv2D(filters=64, kernel_size=(3,3),activation='relu', input_shape=(28,28,1))) # Input Layer
model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))

model.add(MaxPooling2D(pool_size=(2,2))) # MaxPoolinglayer
model.add(Conv2D(filters=128, kernel_size = (3,3), activation='relu'))

model.add(MaxPooling2D(pool_size=(2,2)))   
model.add(Conv2D(filters=256, kernel_size = (3,3), activation="relu"))
    
model.add(MaxPooling2D(pool_size=(2,2)))
    
model.add(Flatten())
model.add(Dense(512,activation="relu"))
    
# Output Layer 
model.add(Dense(10,activation="softmax"))
    
model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])

"""### Data Augmentation"""

# Using to prevent overfitting 

datagen = ImageDataGenerator(featurewise_center=False, 
                             samplewise_center=False, 
                             featurewise_std_normalization=False, 
                             samplewise_std_normalization=False, 
                             zca_whitening=False,
                             rotation_range=15, 
                             zoom_range=0.2,
                             width_shift_range=0.15,
                             height_shift_range=0.15,
                             horizontal_flip=False,
                             vertical_flip=False)

#datagen.fit(X_train)
train_gen = datagen.flow(X_train, y_train, batch_size=batch_size)
test_gen = datagen.flow(X_val, y_val, batch_size=batch_size)

# Model training 
model.fit(X, y, batch_size=batch_size, validation_split=0.2, epochs=10)

# Prediction 
y_pred = model.predict(X_val) # Predict encoded label as integers between 0-9

Y_pred = np.argmax(y_pred, 1) # Decode Predicted labels
Y_test = np.argmax(y_val, 1) # Decode labels
acc_score = accuracy_score(y_true = Y_test, y_pred = Y_pred)
print(acc_score)

# Fit the model 
model_history = model.fit_generator(train_gen,
                                    epochs = epochs,
                                    steps_per_epoch = X_train.shape[0] // batch_size,
                                    validation_data = test_gen,
                                    validation_steps = X_val.shape[0] // batch_size)

# Prediction 
y_pred = model.predict(X_val) # Predict encoded label as integers between 0-9

Y_pred = np.argmax(y_pred, 1) # Decode Predicted labels
Y_test = np.argmax(y_val, 1) # Decode labels
acc_score = accuracy_score(y_true = Y_test, y_pred = Y_pred)
print(acc_score)

# Confusion Matrix 
ig = plt.figure(figsize=(10, 10)) # Set Figure

y_pred = model.predict(X_val) # Predict encoded label as 2 => [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]

Y_pred = np.argmax(y_pred, 1) # Decode Predicted labels
Y_test = np.argmax(y_val, 1) # Decode labels

mat = confusion_matrix(Y_test, Y_pred) # Confusion matrix

# Plot Confusion matrix
sns.heatmap(mat.T, square=True, annot=True, cbar=False, cmap=plt.cm.Blues)
plt.xlabel('Predicted Values')
plt.ylabel('True Values');
plt.show();

# Prediction 
y_pred = model.predict(X_val)
X_val__ = X_val.reshape(X_val.shape[0], 28, 28)

fig, axis = plt.subplots(4, 4, figsize=(12, 14))
for i, ax in enumerate(axis.flat):
    ax.imshow(X_val__[i], cmap='binary')
    ax.set(title = f"Real Number is {y_val[i].argmax()}\nPredict Number is {y_pred[i].argmax()}");

pred = model.predict_classes(test_X, verbose = 1)


{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST Digit Recognizer",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPhSePiTVueAs1heeGGwV3h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prakharrathi25/MNIST-Image-Recognition/blob/master/MNIST_Digit_Recognizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lL08Yp_Dtxeg",
        "colab_type": "text"
      },
      "source": [
        "# MNIST Image Recognition using Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZmcSzt1xoJf",
        "colab_type": "text"
      },
      "source": [
        "### Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VklssldJxOi3",
        "colab_type": "code",
        "outputId": "259157c4-d7e2-4f35-fad2-aa961bad48a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "# Data Manipulation library\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "# Data visualisation libraries\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns \n",
        "\n",
        "# Image Manipulation \n",
        "import cv2 as cv\n",
        "\n",
        "# Evaluation and Splitting \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Deep Learning Libraries\n",
        "import keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout, Conv2D, Lambda, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkDxZgbntnXD",
        "colab_type": "code",
        "outputId": "a5632b12-e87e-4568-c5b0-3d03c2ba26f5",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "# Uploading Data \n",
        "from google.colab import files \n",
        "files.upload() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d0782977-961a-49cf-bd06-fcc9efc97e74\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-d0782977-961a-49cf-bd06-fcc9efc97e74\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test.csv to test.csv\n",
            "Saving train.csv to train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_rvPqXqxMaE",
        "colab_type": "code",
        "outputId": "01182408-f3ee-4fbf-9260-efc1f24f3413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Loading Data \n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# Make original data copies \n",
        "train_og = train_data.copy() \n",
        "test_og = test_data.copy() \n",
        "print(train_data.shape, test_data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 785) (28000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMkTKq34zGfn",
        "colab_type": "code",
        "outputId": "1b817c31-a530-418a-de3d-0d67831d315c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "# Sample of the data \n",
        "print(train_data.head())\n",
        "print(test_data.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   label  pixel0  pixel1  pixel2  ...  pixel780  pixel781  pixel782  pixel783\n",
            "0      1       0       0       0  ...         0         0         0         0\n",
            "1      0       0       0       0  ...         0         0         0         0\n",
            "2      1       0       0       0  ...         0         0         0         0\n",
            "3      4       0       0       0  ...         0         0         0         0\n",
            "4      0       0       0       0  ...         0         0         0         0\n",
            "\n",
            "[5 rows x 785 columns]\n",
            "   pixel0  pixel1  pixel2  pixel3  ...  pixel780  pixel781  pixel782  pixel783\n",
            "0       0       0       0       0  ...         0         0         0         0\n",
            "1       0       0       0       0  ...         0         0         0         0\n",
            "2       0       0       0       0  ...         0         0         0         0\n",
            "3       0       0       0       0  ...         0         0         0         0\n",
            "4       0       0       0       0  ...         0         0         0         0\n",
            "\n",
            "[5 rows x 784 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTw-NuOVzP8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extract only the features \n",
        "X = train_data.drop(['label'], axis = 1).values\n",
        "y = train_data['label'].values\n",
        "test_X = test_data.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azYabRis3LC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Grayscale Normalization \n",
        "X = X / 255.0\n",
        "test_X = test_X / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac0A6-B-3U_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape the image data into 3 dimensions (height = 28pixels, width = 28px, 1)\n",
        "# because 28 x 28 = 784 \n",
        "X = X.reshape(-1, 28, 28, 1)\n",
        "test_X = test_X.reshape(-1, 28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2j3Oi-R3-H2",
        "colab_type": "text"
      },
      "source": [
        "### Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wjLX6kv4Jj9",
        "colab_type": "code",
        "outputId": "dda52c33-2aa5-441c-f86f-5bffb05c3404",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# One hot encode the labels. There are 10 labels so we add 10 new dimensions\n",
        "y = to_categorical(y)\n",
        "print(y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MC7I4QN4sgc",
        "colab_type": "code",
        "outputId": "3b07e57d-47ab-4e5e-9a86-61f5dc173667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Train and validation splits \n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=324)\n",
        "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(31500, 28, 28, 1) (31500, 10) (10500, 28, 28, 1) (10500, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5VC-9Eu7spx",
        "colab_type": "code",
        "outputId": "c5324da2-192e-4543-e7f5-304d7544494f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "# Visulaisation of the data \n",
        "images = X_train.reshape(X_train.shape[0], 28, 28)\n",
        "\n",
        "fig, axis = plt.subplots(1, 5, figsize=(20, 10))\n",
        "for i, ax in enumerate(axis.flat):\n",
        "    ax.imshow(images[i], cmap = 'binary')\n",
        "    digit = y_train[i].argmax()   # finding the number where the array has a 1 which will be the max value\n",
        "    ax.set(title = f\"The number is {digit}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABH4AAADvCAYAAACEwBPsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1440x720 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzyI4yZUBtfF",
        "colab_type": "text"
      },
      "source": [
        "## Building the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xqTKNvn9gXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Important parameters\n",
        "epochs = 50\n",
        "batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-NLve04C24K",
        "colab_type": "code",
        "outputId": "bfc4298a-cd71-4232-bbe5-d74cd0301c26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "source": [
        "# Building the CNN Model\n",
        "model = Sequential() \n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3),activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) # MaxPoolinglayer\n",
        "\n",
        "#model.add(Conv2D(filters=128, kernel_size = (3,3), activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "# model.add(MaxPooling2D(pool_size=(2,2)))    \n",
        "# model.add(Conv2D(filters=256, kernel_size = (3,3), activation=\"relu\"))\n",
        "    \n",
        "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    \n",
        "model.add(Flatten())\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Dense(512,activation=\"relu\"))\n",
        "    \n",
        "model.add(Dense(10,activation=\"softmax\"))\n",
        "    \n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_19 (Conv2D)           (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 24, 24, 64)        36928     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                92170     \n",
            "=================================================================\n",
            "Total params: 129,738\n",
            "Trainable params: 129,738\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Rxgwej0Iy0u",
        "colab_type": "text"
      },
      "source": [
        "### Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKSKnqIGI0lz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using to prevent overfitting \n",
        "\n",
        "datagen = ImageDataGenerator(featurewise_center=False, \n",
        "                             samplewise_center=False, \n",
        "                             featurewise_std_normalization=False, \n",
        "                             samplewise_std_normalization=False, \n",
        "                             zca_whitening=False,\n",
        "                             rotation_range=10, \n",
        "                             zoom_range=0.1,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1,\n",
        "                             horizontal_flip=False,\n",
        "                             vertical_flip=False)\n",
        "\n",
        "#datagen.fit(X_train)\n",
        "train_gen = datagen.flow(X_train, y_train, batch_size=batch_size)\n",
        "test_gen = datagen.flow(X_val, y_val, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_faEMHaKVDu",
        "colab_type": "code",
        "outputId": "4aa65d47-b758-4699-cc9d-d3b1bfe424fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        }
      },
      "source": [
        "# Model training \n",
        "model.fit(X, y, batch_size=batch_size, validation_split=0.2, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 33600 samples, validate on 8400 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "33600/33600 [==============================] - 208s 6ms/step - loss: 0.2400 - acc: 0.9226 - val_loss: 0.0648 - val_acc: 0.9796\n",
            "Epoch 2/10\n",
            "33600/33600 [==============================] - 208s 6ms/step - loss: 0.0742 - acc: 0.9776 - val_loss: 0.0732 - val_acc: 0.9774\n",
            "Epoch 3/10\n",
            "33600/33600 [==============================] - 209s 6ms/step - loss: 0.0534 - acc: 0.9832 - val_loss: 0.0702 - val_acc: 0.9820\n",
            "Epoch 4/10\n",
            "33600/33600 [==============================] - 207s 6ms/step - loss: 0.0382 - acc: 0.9881 - val_loss: 0.0510 - val_acc: 0.9857\n",
            "Epoch 5/10\n",
            "33600/33600 [==============================] - 207s 6ms/step - loss: 0.0353 - acc: 0.9890 - val_loss: 0.0538 - val_acc: 0.9860\n",
            "Epoch 6/10\n",
            "33600/33600 [==============================] - 203s 6ms/step - loss: 0.0336 - acc: 0.9897 - val_loss: 0.0639 - val_acc: 0.9810\n",
            "Epoch 7/10\n",
            "33600/33600 [==============================] - 201s 6ms/step - loss: 0.0317 - acc: 0.9907 - val_loss: 0.0394 - val_acc: 0.9904\n",
            "Epoch 8/10\n",
            "33600/33600 [==============================] - 202s 6ms/step - loss: 0.0251 - acc: 0.9928 - val_loss: 0.0676 - val_acc: 0.9856\n",
            "Epoch 9/10\n",
            "33600/33600 [==============================] - 203s 6ms/step - loss: 0.0278 - acc: 0.9922 - val_loss: 0.0968 - val_acc: 0.9811\n",
            "Epoch 10/10\n",
            "33600/33600 [==============================] - 203s 6ms/step - loss: 0.0243 - acc: 0.9934 - val_loss: 0.0807 - val_acc: 0.9838\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe067cddcf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qid8CbosX9H-",
        "colab_type": "code",
        "outputId": "66a24219-3ad4-4a2a-9a66-97304b5348fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Prediction \n",
        "y_pred = model.predict(X_val) # Predict encoded label as integers between 0-9\n",
        "\n",
        "Y_pred = np.argmax(y_pred, 1) # Decode Predicted labels\n",
        "Y_test = np.argmax(y_val, 1) # Decode labels\n",
        "acc_score = accuracy_score(y_true = Y_test, y_pred = Y_pred)\n",
        "print(acc_score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9897142857142858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqV4Jx8BqTIM",
        "colab_type": "code",
        "outputId": "89fbb567-706f-49a4-e3a5-c8b1a6f3ca33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "# Printing Model Summary\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 24, 24, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 10, 10, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 3, 3, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 543,306\n",
            "Trainable params: 543,306\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0fY2EWLKwDy",
        "colab_type": "code",
        "outputId": "5bfdb81e-17fc-4095-b8e8-23646196abd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Fit the model \n",
        "model_history = model.fit_generator(train_gen,\n",
        "                                    epochs = epochs,\n",
        "                                    steps_per_epoch = X_train.shape[0] // batch_size,\n",
        "                                    validation_data = test_gen,\n",
        "                                    validation_steps = X_val.shape[0] // batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "492/492 [==============================] - 203s 413ms/step - loss: 0.1172 - acc: 0.9662 - val_loss: 0.0870 - val_acc: 0.9762\n",
            "Epoch 2/50\n",
            "492/492 [==============================] - 200s 407ms/step - loss: 0.0751 - acc: 0.9783 - val_loss: 0.0713 - val_acc: 0.9797\n",
            "Epoch 3/50\n",
            "492/492 [==============================] - 202s 410ms/step - loss: 0.0648 - acc: 0.9810 - val_loss: 0.0545 - val_acc: 0.9857\n",
            "Epoch 4/50\n",
            "492/492 [==============================] - 201s 408ms/step - loss: 0.0571 - acc: 0.9834 - val_loss: 0.0562 - val_acc: 0.9847\n",
            "Epoch 5/50\n",
            "492/492 [==============================] - 201s 408ms/step - loss: 0.0555 - acc: 0.9829 - val_loss: 0.0651 - val_acc: 0.9805\n",
            "Epoch 6/50\n",
            "492/492 [==============================] - 201s 408ms/step - loss: 0.0496 - acc: 0.9848 - val_loss: 0.0567 - val_acc: 0.9848\n",
            "Epoch 7/50\n",
            "492/492 [==============================] - 202s 410ms/step - loss: 0.0461 - acc: 0.9871 - val_loss: 0.0545 - val_acc: 0.9854\n",
            "Epoch 8/50\n",
            "492/492 [==============================] - 201s 409ms/step - loss: 0.0470 - acc: 0.9861 - val_loss: 0.0505 - val_acc: 0.9856\n",
            "Epoch 9/50\n",
            "492/492 [==============================] - 203s 412ms/step - loss: 0.0437 - acc: 0.9878 - val_loss: 0.0467 - val_acc: 0.9874\n",
            "Epoch 10/50\n",
            "492/492 [==============================] - 203s 412ms/step - loss: 0.0424 - acc: 0.9872 - val_loss: 0.0564 - val_acc: 0.9860\n",
            "Epoch 11/50\n",
            "492/492 [==============================] - 202s 410ms/step - loss: 0.0475 - acc: 0.9871 - val_loss: 0.0599 - val_acc: 0.9846\n",
            "Epoch 12/50\n",
            "492/492 [==============================] - 200s 407ms/step - loss: 0.0381 - acc: 0.9888 - val_loss: 0.0487 - val_acc: 0.9862\n",
            "Epoch 13/50\n",
            "492/492 [==============================] - 200s 406ms/step - loss: 0.0429 - acc: 0.9872 - val_loss: 0.0585 - val_acc: 0.9860\n",
            "Epoch 14/50\n",
            "492/492 [==============================] - 200s 407ms/step - loss: 0.0383 - acc: 0.9887 - val_loss: 0.0498 - val_acc: 0.9873\n",
            "Epoch 15/50\n",
            "492/492 [==============================] - 201s 408ms/step - loss: 0.0363 - acc: 0.9899 - val_loss: 0.0490 - val_acc: 0.9878\n",
            "Epoch 16/50\n",
            "492/492 [==============================] - 201s 409ms/step - loss: 0.0418 - acc: 0.9888 - val_loss: 0.0513 - val_acc: 0.9867\n",
            "Epoch 17/50\n",
            "492/492 [==============================] - 201s 409ms/step - loss: 0.0376 - acc: 0.9899 - val_loss: 0.0621 - val_acc: 0.9871\n",
            "Epoch 18/50\n",
            "492/492 [==============================] - 202s 410ms/step - loss: 0.0367 - acc: 0.9895 - val_loss: 0.0444 - val_acc: 0.9890\n",
            "Epoch 19/50\n",
            "492/492 [==============================] - 201s 409ms/step - loss: 0.0366 - acc: 0.9903 - val_loss: 0.0486 - val_acc: 0.9881\n",
            "Epoch 20/50\n",
            "492/492 [==============================] - 201s 409ms/step - loss: 0.0345 - acc: 0.9902 - val_loss: 0.0385 - val_acc: 0.9894\n",
            "Epoch 21/50\n",
            "492/492 [==============================] - 202s 411ms/step - loss: 0.0338 - acc: 0.9906 - val_loss: 0.0395 - val_acc: 0.9898\n",
            "Epoch 22/50\n",
            "492/492 [==============================] - 202s 411ms/step - loss: 0.0287 - acc: 0.9915 - val_loss: 0.0505 - val_acc: 0.9888\n",
            "Epoch 23/50\n",
            "492/492 [==============================] - 201s 408ms/step - loss: 0.0337 - acc: 0.9906 - val_loss: 0.0595 - val_acc: 0.9840\n",
            "Epoch 24/50\n",
            "492/492 [==============================] - 200s 406ms/step - loss: 0.0338 - acc: 0.9909 - val_loss: 0.0396 - val_acc: 0.9901\n",
            "Epoch 25/50\n",
            "492/492 [==============================] - 199s 404ms/step - loss: 0.0300 - acc: 0.9913 - val_loss: 0.0494 - val_acc: 0.9854\n",
            "Epoch 26/50\n",
            "492/492 [==============================] - 201s 408ms/step - loss: 0.0306 - acc: 0.9910 - val_loss: 0.0466 - val_acc: 0.9889\n",
            "Epoch 27/50\n",
            "492/492 [==============================] - 201s 408ms/step - loss: 0.0302 - acc: 0.9920 - val_loss: 0.0507 - val_acc: 0.9875\n",
            "Epoch 28/50\n",
            "492/492 [==============================] - 201s 409ms/step - loss: 0.0276 - acc: 0.9920 - val_loss: 0.0489 - val_acc: 0.9876\n",
            "Epoch 29/50\n",
            "492/492 [==============================] - 200s 407ms/step - loss: 0.0268 - acc: 0.9915 - val_loss: 0.0448 - val_acc: 0.9908\n",
            "Epoch 30/50\n",
            "492/492 [==============================] - 202s 410ms/step - loss: 0.0300 - acc: 0.9916 - val_loss: 0.0445 - val_acc: 0.9897\n",
            "Epoch 31/50\n",
            "492/492 [==============================] - 202s 410ms/step - loss: 0.0266 - acc: 0.9927 - val_loss: 0.0448 - val_acc: 0.9902\n",
            "Epoch 32/50\n",
            "492/492 [==============================] - 200s 406ms/step - loss: 0.0300 - acc: 0.9920 - val_loss: 0.0510 - val_acc: 0.9870\n",
            "Epoch 33/50\n",
            "492/492 [==============================] - 200s 406ms/step - loss: 0.0242 - acc: 0.9932 - val_loss: 0.0472 - val_acc: 0.9880\n",
            "Epoch 34/50\n",
            "492/492 [==============================] - 198s 403ms/step - loss: 0.0325 - acc: 0.9906 - val_loss: 0.0503 - val_acc: 0.9873\n",
            "Epoch 35/50\n",
            "492/492 [==============================] - 201s 409ms/step - loss: 0.0276 - acc: 0.9927 - val_loss: 0.0571 - val_acc: 0.9886\n",
            "Epoch 36/50\n",
            "492/492 [==============================] - 201s 408ms/step - loss: 0.0266 - acc: 0.9927 - val_loss: 0.0467 - val_acc: 0.9906\n",
            "Epoch 37/50\n",
            "492/492 [==============================] - 202s 410ms/step - loss: 0.0270 - acc: 0.9928 - val_loss: 0.0476 - val_acc: 0.9899\n",
            "Epoch 38/50\n",
            "492/492 [==============================] - 201s 409ms/step - loss: 0.0313 - acc: 0.9917 - val_loss: 0.0513 - val_acc: 0.9887\n",
            "Epoch 39/50\n",
            "492/492 [==============================] - 202s 411ms/step - loss: 0.0317 - acc: 0.9922 - val_loss: 0.0471 - val_acc: 0.9897\n",
            "Epoch 40/50\n",
            "492/492 [==============================] - 203s 412ms/step - loss: 0.0274 - acc: 0.9926 - val_loss: 0.0426 - val_acc: 0.9898\n",
            "Epoch 41/50\n",
            "492/492 [==============================] - 203s 413ms/step - loss: 0.0260 - acc: 0.9928 - val_loss: 0.0505 - val_acc: 0.9886\n",
            "Epoch 42/50\n",
            "492/492 [==============================] - 200s 407ms/step - loss: 0.0243 - acc: 0.9935 - val_loss: 0.0533 - val_acc: 0.9897\n",
            "Epoch 43/50\n",
            "492/492 [==============================] - 201s 408ms/step - loss: 0.0264 - acc: 0.9929 - val_loss: 0.0441 - val_acc: 0.9904\n",
            "Epoch 44/50\n",
            "492/492 [==============================] - 201s 408ms/step - loss: 0.0225 - acc: 0.9938 - val_loss: 0.0478 - val_acc: 0.9914\n",
            "Epoch 45/50\n",
            "492/492 [==============================] - 201s 408ms/step - loss: 0.0321 - acc: 0.9919 - val_loss: 0.0664 - val_acc: 0.9866\n",
            "Epoch 46/50\n",
            "492/492 [==============================] - 202s 411ms/step - loss: 0.0285 - acc: 0.9921 - val_loss: 0.0534 - val_acc: 0.9885\n",
            "Epoch 47/50\n",
            "492/492 [==============================] - 201s 408ms/step - loss: 0.0252 - acc: 0.9933 - val_loss: 0.0552 - val_acc: 0.9893\n",
            "Epoch 48/50\n",
            "492/492 [==============================] - 200s 407ms/step - loss: 0.0264 - acc: 0.9929 - val_loss: 0.0579 - val_acc: 0.9874\n",
            "Epoch 49/50\n",
            "492/492 [==============================] - 201s 409ms/step - loss: 0.0229 - acc: 0.9935 - val_loss: 0.0495 - val_acc: 0.9892\n",
            "Epoch 50/50\n",
            "492/492 [==============================] - 202s 411ms/step - loss: 0.0233 - acc: 0.9935 - val_loss: 0.0544 - val_acc: 0.9889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_kvljT3YmTw",
        "colab_type": "code",
        "outputId": "e36341e6-b2f2-4c4e-c4de-82a84376713e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Prediction \n",
        "y_pred = model.predict(X_val) # Predict encoded label as integers between 0-9\n",
        "\n",
        "Y_pred = np.argmax(y_pred, 1) # Decode Predicted labels\n",
        "Y_test = np.argmax(y_val, 1) # Decode labels\n",
        "acc_score = accuracy_score(y_true = Y_test, y_pred = Y_pred)\n",
        "print(acc_score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9926666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnxxHjj72Ypn",
        "colab_type": "code",
        "outputId": "9c6134bf-26ad-4dab-ecb0-1498b4a3aefb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 24, 24, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 10, 10, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 3, 3, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 543,306\n",
            "Trainable params: 543,306\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SFfcVjm_ZKB",
        "colab_type": "text"
      },
      "source": [
        "## Low Parameter Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnL6pQY__cK7",
        "colab_type": "code",
        "outputId": "b7032230-9b63-4b1a-d8f7-5ddbb2db5b00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "# Create model\n",
        "model3 = Sequential(\n",
        "#   Conv2D(8, (7,7),strides=(1, 1), activation='relu', input_shape=(28, 28, 1)),\n",
        "#   MaxPooling2D(5, 5),\n",
        "#   Flatten(),\n",
        "#   Dense(10, activation='softmax')\n",
        ")\n",
        "model3.add(Conv2D(filters=8, kernel_size=(3,3),activation='relu', input_shape=(28,28,1)))\n",
        "model3.add(Conv2D(filters=8, kernel_size=(3,3), activation='relu'))\n",
        "model3.add(Dropout(0.1))\n",
        "model3.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(10, activation='softmax'))\n",
        "# Compile and summarize\n",
        "model3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model3.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_27 (Conv2D)           (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 24, 24, 8)         584       \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 24, 24, 8)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 12, 12, 8)         0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                11530     \n",
            "=================================================================\n",
            "Total params: 12,194\n",
            "Trainable params: 12,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF0HcAUO_lXS",
        "colab_type": "code",
        "outputId": "666d60e6-796f-4f9e-cfec-14a1cc4c2a64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the model\n",
        "x1 = train_og.drop(labels = [\"label\"],axis = 1) \n",
        "x1=x1.values.reshape(-1, 28, 28, 1)\n",
        "x1 = x1 / 255.0\n",
        "y1 = train_og['label']\n",
        "model3.fit(x1, y1, epochs=30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "42000/42000 [==============================] - 28s 656us/step - loss: 0.2703 - acc: 0.9196\n",
            "Epoch 2/30\n",
            "42000/42000 [==============================] - 27s 640us/step - loss: 0.1086 - acc: 0.9670\n",
            "Epoch 3/30\n",
            "42000/42000 [==============================] - 27s 641us/step - loss: 0.0845 - acc: 0.9751\n",
            "Epoch 4/30\n",
            "42000/42000 [==============================] - 27s 634us/step - loss: 0.0673 - acc: 0.9794\n",
            "Epoch 5/30\n",
            "42000/42000 [==============================] - 26s 628us/step - loss: 0.0566 - acc: 0.9823\n",
            "Epoch 6/30\n",
            "42000/42000 [==============================] - 26s 631us/step - loss: 0.0468 - acc: 0.9856\n",
            "Epoch 7/30\n",
            "42000/42000 [==============================] - 27s 631us/step - loss: 0.0414 - acc: 0.9875\n",
            "Epoch 8/30\n",
            "42000/42000 [==============================] - 26s 624us/step - loss: 0.0363 - acc: 0.9886\n",
            "Epoch 9/30\n",
            "42000/42000 [==============================] - 26s 626us/step - loss: 0.0330 - acc: 0.9891\n",
            "Epoch 10/30\n",
            "42000/42000 [==============================] - 26s 624us/step - loss: 0.0301 - acc: 0.9905\n",
            "Epoch 11/30\n",
            "42000/42000 [==============================] - 27s 633us/step - loss: 0.0269 - acc: 0.9912\n",
            "Epoch 12/30\n",
            "42000/42000 [==============================] - 26s 625us/step - loss: 0.0246 - acc: 0.9920\n",
            "Epoch 13/30\n",
            "42000/42000 [==============================] - 27s 642us/step - loss: 0.0231 - acc: 0.9927\n",
            "Epoch 14/30\n",
            "42000/42000 [==============================] - 27s 647us/step - loss: 0.0198 - acc: 0.9936\n",
            "Epoch 15/30\n",
            "42000/42000 [==============================] - 27s 654us/step - loss: 0.0194 - acc: 0.9936\n",
            "Epoch 16/30\n",
            "42000/42000 [==============================] - 27s 651us/step - loss: 0.0172 - acc: 0.9946\n",
            "Epoch 17/30\n",
            "42000/42000 [==============================] - 27s 648us/step - loss: 0.0167 - acc: 0.9942\n",
            "Epoch 18/30\n",
            "42000/42000 [==============================] - 27s 653us/step - loss: 0.0155 - acc: 0.9947\n",
            "Epoch 19/30\n",
            "42000/42000 [==============================] - 27s 647us/step - loss: 0.0151 - acc: 0.9951\n",
            "Epoch 20/30\n",
            "42000/42000 [==============================] - 27s 640us/step - loss: 0.0136 - acc: 0.9955\n",
            "Epoch 21/30\n",
            "42000/42000 [==============================] - 27s 641us/step - loss: 0.0135 - acc: 0.9957\n",
            "Epoch 22/30\n",
            "42000/42000 [==============================] - 27s 633us/step - loss: 0.0139 - acc: 0.9954\n",
            "Epoch 23/30\n",
            "42000/42000 [==============================] - 26s 630us/step - loss: 0.0128 - acc: 0.9954\n",
            "Epoch 24/30\n",
            "42000/42000 [==============================] - 27s 640us/step - loss: 0.0108 - acc: 0.9965\n",
            "Epoch 25/30\n",
            "42000/42000 [==============================] - 27s 642us/step - loss: 0.0106 - acc: 0.9965\n",
            "Epoch 26/30\n",
            "42000/42000 [==============================] - 27s 635us/step - loss: 0.0104 - acc: 0.9965\n",
            "Epoch 27/30\n",
            "42000/42000 [==============================] - 27s 640us/step - loss: 0.0111 - acc: 0.9961\n",
            "Epoch 28/30\n",
            "42000/42000 [==============================] - 27s 638us/step - loss: 0.0101 - acc: 0.9966\n",
            "Epoch 29/30\n",
            "42000/42000 [==============================] - 27s 640us/step - loss: 0.0086 - acc: 0.9972\n",
            "Epoch 30/30\n",
            "42000/42000 [==============================] - 27s 640us/step - loss: 0.0095 - acc: 0.9969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe058b25940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtbRSonr_rXE",
        "colab_type": "code",
        "outputId": "1bd3fd66-22dc-4091-d41d-8c92477e5286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Prediction \n",
        "y_pred = model3.predict(X_val) # Predict encoded label as integers between 0-9\n",
        "\n",
        "Y_pred = np.argmax(y_pred, 1) # Decode Predicted labels\n",
        "Y_test = np.argmax(y_val, 1) # Decode labels\n",
        "acc_score = accuracy_score(y_true = Y_test, y_pred = Y_pred)\n",
        "print(acc_score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9990476190476191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bByznN_cL9c8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prediction \n",
        "y_pred = model.predict(X_val)\n",
        "X_val__ = X_val.reshape(X_val.shape[0], 28, 28)\n",
        "\n",
        "fig, axis = plt.subplots(4, 4, figsize=(12, 14))\n",
        "for i, ax in enumerate(axis.flat):\n",
        "    ax.imshow(X_val__[i], cmap='binary')\n",
        "    ax.set(title = f\"Real Number is {y_val[i].argmax()}\\nPredict Number is {y_pred[i].argmax()}\");"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUB9r5UdMGr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict_classes(test_X, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-QzNivNMLfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}